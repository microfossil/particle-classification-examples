{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Ycmylt-ISHE"
   },
   "source": [
    "# Welcome\n",
    "\n",
    "This python notebook is a step-by-step guide to training a neural network on Google Colab using the *MISO* particle classification library.\n",
    "\n",
    "The MISO library is a set of python scripts that simplify creating, training and saving a convolutional neural network (CNN) primarily for particle images, such as foraminifera.\n",
    "\n",
    "The MISO library can be used to train common CNN topologies such as ResNet. It also includes two custom full CNN designs, \"base_cyclic\" and \"resnet_cyclic\", that were developed at CEREGE and give good results with quick training time, and a ResNet50 transfer learning method that is extremely fast to train.\n",
    "\n",
    "Training assumes single particle images with the particles roughly centred in the image, and saved in jpeg, bmp, tiff or png format.\n",
    "\n",
    "**Note:** The notebook is interactive - you run the code inside it. Code cells are coloured light grey. To run a cell, hover the mouse above it and click the play arrow in the top-left corner.\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "# Getting Started\n",
    "\n",
    "## Save a copy (recommended)\n",
    "\n",
    "If you want to keep a copy of this notebook and any changes you make, please make a copy:\n",
    "\n",
    "*   Click *File* -> *Save a copy in Drive...* to save this notebook in your Google Drive.\n",
    "*   A new Google Colab tab will open up with a copy of the notebook.\n",
    "*   Click *File* -> *Rename...* to give the notebook a more memorable name.\n",
    "\n",
    "## Enabling the GPU (Important)\n",
    "\n",
    "For fast training we need to enable the GPU. \n",
    "\n",
    "In the menu bar of the Google Colab webpage, click *Runtime* -> *Change runtime type* and in the dialog that pops up, change *Hardware accelerator* to *GPU*. Click save to restart Google Colab with a GPU.\n",
    "\n",
    "**Note:** You can check which GPU has been enabled using the `!nvidia-smi` command. The `T4` is 3-4 times faster than the `K80`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7072,
     "status": "ok",
     "timestamp": 1565865848998,
     "user": {
      "displayName": "Ross Marchant",
      "photoUrl": "",
      "userId": "18161906969163655277"
     },
     "user_tz": -600
    },
    "id": "RC4iePqExWwO",
    "outputId": "6d352773-caa0-408a-920e-2d91e73af86a",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "369hf0uij2aU"
   },
   "source": [
    "## MISO library\n",
    "\n",
    "The MISO python library contains the code for creating and training the neural networks. It uses **Tensorflow version 1.14 / 1.15.X**.\n",
    "\n",
    "Run the cell below to set the Tensorflow version and install the latest version of MISO from its bitbucket repository.\n",
    "\n",
    "**Note:** Google Colab will prompt you (at the bottom of the cell) to restart the runtime if you have already installed the library this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9975,
     "status": "ok",
     "timestamp": 1565865860922,
     "user": {
      "displayName": "Ross Marchant",
      "photoUrl": "",
      "userId": "18161906969163655277"
     },
     "user_tz": -600
    },
    "id": "iwndK5weDskf",
    "outputId": "b7a45e7c-d38c-4a2a-c7bc-61852a57a925",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "!pip install -U git+https://www.github.com/microfossil/particle-classification.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iWr-2GtIvaL"
   },
   "source": [
    "***\n",
    "\n",
    "***\n",
    "\n",
    "# Dataset\n",
    "\n",
    "## Preparation\n",
    "\n",
    "The training set consists of images of the classes to classify, sorted into directories by class name.\n",
    "\n",
    "For detailed instructions on constructing a training set please see [this tutorial][1]. _ParticleTrieur_ is a cross-platform java app to help create training sets, it can be downloaded from [here][2].\n",
    "\n",
    "[1]: https://particle-classification.readthedocs.io/en/latest/tutorial/dataset_creation.html\n",
    "[2]: https://particle-classification.readthedocs.io\n",
    "\n",
    "**Structure**\n",
    "\n",
    "The structure of the dataset must be a 1) single root folder with the dataset name, containing 2) a subfolder for each class, with the same name as the class, and 3) all the images for that class inside of it.\n",
    "\n",
    "## Make available to Google Colab\n",
    "\n",
    "To use an image dataset for training, it must be accessable to Google Colab\n",
    "\n",
    "There are three method to do this\n",
    "\n",
    "1.   Zip the dataset and upload it to a sharing site that supports direct links, such as Dropbox, Onedrive, Owncloud, Nuage, etc. *Google Drive does not work*\n",
    "2.   Upload the dataset to Google Drive\n",
    "3.   Zip the dataset and upload it to Google Colab (not recommended)\n",
    "\n",
    "\n",
    "**Before continuing**\n",
    "\n",
    "If not already open, click the small arrow under the Colab icon (CO) in the upper left corner of the webpage to open the left pane, and then go to the *Files* tab.\n",
    "\n",
    "## Method 1: Upload to Dropbox / OneDrive / OwnCloud / Nuage etc\n",
    "\n",
    "This method is quick, doesn't require Google Drive installed, and you can share the link to the training set with other people.\n",
    "\n",
    "It does not work with Google Drive, as it is currently impossible to get a direct download link for large datasets.\n",
    "\n",
    "### 1. Create a zip file\n",
    "\n",
    "We must create a zip file of the dataset\n",
    "\n",
    "Make sure the name of the root folder is a unique name that will not conflict with any other dataset.\n",
    "\n",
    "Compress the root folder of the dataset into a .zip file\n",
    "\n",
    "Windows: Right-click the root folder, then click *Send to --> Compressed (zipped) folder*\n",
    "\n",
    "Mac: Right-click the root folder, then click *Compress items*\n",
    "\n",
    "### 2. Upload\n",
    "\n",
    "Upload the zip file onto your favourite cloud sharing provider, e.g. Dropbox or Onedrive\n",
    "\n",
    "### 3. Create a sharing link\n",
    "\n",
    "Once the file has finished uploading or syncing, create a sharing link for the file.\n",
    "\n",
    "For example, in Dropbox in Windows, right-click your zip file in the dropbox folder and select Copy Dropbox Link.\n",
    "\n",
    "If you have the option to set permissions for the link (e.g. with OneDrive) make sure they are read-only so that you can share the data without others being able to edit it.\n",
    "\n",
    "### 4. Convert the link into a direct download link\n",
    "\n",
    "For some sharing services such as Dropbox and Onedrive, the sharing link points to a *website* where you can download the file. We need a link that goes directly to the file instead.\n",
    "\n",
    "Thus, the link must be changed from the website link to the direct download link.\n",
    "\n",
    "**Dropbox:**\n",
    "\n",
    "Change www.dropbox.com to dl.dropboxusercontent.com:\n",
    "\n",
    "For example,\n",
    "\n",
    "https://www.dropbox.com/s/wlxcp29u8t0z9yw/DummyFile.TXT?dl=0\n",
    "\n",
    "becomes\n",
    "\n",
    "https://dl.dropboxusercontent.com/s/wlxcp29u8t0z9yw/DummyFile.TXT?dl=0\n",
    "\n",
    "**OneDrive:**\n",
    "\n",
    "Change the ms in the first part of the link to ws.\n",
    "\n",
    "For example,\n",
    "\n",
    "https://1drv.ms/u/s!AiQM7sVIv7fah4IZlw0GmHAwmOT9DY\n",
    "\n",
    "becomes\n",
    "\n",
    "https://1drv.ws/u/s!AiQM7sVIv7fah4IZlw0GmHAwmOT9DY\n",
    "\n",
    "**Nuage / Owncloud:**\n",
    "\n",
    "Add `/download` to the end of the link.\n",
    "\n",
    "For example,\n",
    "\n",
    "https://nuage.osupytheas.fr/s/crYrKyXdQqAR5E6\n",
    "\n",
    "becomes\n",
    "\n",
    "https://nuage.osupytheas.fr/s/crYrKyXdQqAR5E6/download\n",
    "\n",
    "**Other services:**\n",
    "\n",
    "For other services, check if the sharing link is a direct download link by pasting it into the address bar of your internet browser and pressing enter.\n",
    "\n",
    "If the zip file starts downloading, it is a direct download link already, and nothing needs to be changed. If it goes to a website, you may need to search how to create a direct download link for you particular service. Not that for Google Drive files there is currently no way to create a direct download link for large files (it will go to a anti-virus confirmation website)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSfqMSnoat04"
   },
   "source": [
    "## Method 2: Upload to Google Drive\n",
    "\n",
    "Googe Drive is a sharing service that gives you about 15GB of storage. Everyone with a Google account automatically has a Google Drive account. \n",
    "\n",
    "### 1. Upload\n",
    "\n",
    "There is no need to create a zip file with this method.\n",
    "\n",
    "Instead, create a `datasets` directory on your Google Drive and save the root folder to it. This can either be done online, or by syncing with Google Drive on your computer.\n",
    "\n",
    "To download Google Drive, go to https://drive.google.com/drive/my-drive, click the settings icon (gear icon in top right) and then click *Get Backup and Sync for Windows*.\n",
    "\n",
    "### 2. Mount\n",
    "\n",
    "Run the cell below to mount your google drive on Google Colab. Once mounted, all your files on Google Drive are accessable from the *Files* tab on the left under `/content/drive`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n36XODPXan0H",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNWPJWJufgva"
   },
   "source": [
    "\n",
    "## Method 3: Transfer from your computer\n",
    "\n",
    "You can transfer the images directly from your computer and save them on Google Colab. \n",
    "\n",
    "The disadvantages of this method are that ploading the data can be slow and it is deleted from Google Colab when the session ends.\n",
    "\n",
    "### 1. Create a zip file\n",
    "\n",
    "We must create a zip file of the dataset as for the first method.\n",
    "\n",
    "Make sure the name of the root folder is a unique name that will not conflict with any other dataset.\n",
    "\n",
    "Compress the root folder of the dataset into a .zip file\n",
    "\n",
    "Windows: Right-click the root folder, then click Send to --> Compressed (zipped) folder\n",
    "\n",
    "Mac: Right-click the root folder, then click Compress items\n",
    "\n",
    "### 2. Create directory\n",
    "\n",
    "Now we create a directory called `datasets` in Google Colab by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scXgjwLtV17C",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/content/datasets/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MU53m21IZT7b"
   },
   "source": [
    "Click *Refresh* in the *Files* tab in the left pane of the Google Colab screen. You should see  a new directory called datasets that contains the dataset folder.\n",
    "\n",
    "### 3. Upload\n",
    "\n",
    "In the *Files* tab in the left pane of Google Colab, right-click the newly created *datasets* directory and click *Upload*.\n",
    "\n",
    "Choose the zip file and start the upload. The progress is shown at the bottom of the *Files* tab.\n",
    "\n",
    "### 4. Unzip\n",
    "\n",
    "Once the file has uploaded, right-click the zip filename in the *Files* pane, and click *Copy path*.\n",
    "\n",
    "Paste the copied path in the cell below (replacing PASTE_HERE) and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1s5XkbVcB71",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!unzip PASTE_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbpIfpJ7fHjj"
   },
   "source": [
    "You should see a new folder *drive* in the *Files* tab. If not, click *Refresh*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-FLidQAkdsc"
   },
   "source": [
    "***\n",
    "\n",
    "***\n",
    "\n",
    "# Training\n",
    "\n",
    "We are now ready to configure the network and begin training!\n",
    "\n",
    "We shall use the simple training interface provided by the MISO python library.\n",
    "\n",
    "It allows us to train the dataset using a variety of pre-made neural network topologies. The results and the trained neural network are saved on Google Colab for download.\n",
    "\n",
    "**Note:** The directories on Google Colab are cleared after each session. Remember to download the results before quitting!\n",
    "\n",
    "## Configuration\n",
    "\n",
    "### 1. Setup\n",
    "\n",
    "First we load the training method and create a dictionary to hold the configuration parameters.\n",
    "\n",
    "The `default_params` function is used to initialise the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5324,
     "status": "ok",
     "timestamp": 1565865878262,
     "user": {
      "displayName": "Ross Marchant",
      "photoUrl": "",
      "userId": "18161906969163655277"
     },
     "user_tz": -600
    },
    "id": "oIyj-kV5mVix",
    "outputId": "bdf1b5ee-825e-446a-d808-fbadc4a605a6",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "from miso.training.model_trainer import train_image_classification_model\n",
    "from miso.training.model_params import default_params\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "params = default_params()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_bedphLXk4-o"
   },
   "source": [
    "\n",
    "\n",
    "Add a short name and description for the network.\n",
    "\n",
    "*   The short name will be used to identify the network and construct the output save directory.\n",
    "*   The description can be a more in-depth summary of the network and dataset. Set to *None* to have the description automatically generated.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5CtNXhpk1j3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params['name'] = 'google_colab_example'\n",
    "params['description'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ht3qh8hq17e"
   },
   "source": [
    "### 2. Input Source\n",
    "\n",
    "Configure the location of the training set according to the method used to upload previously:\n",
    "\n",
    "**Zip file on Dropbox / OneDrive / OwnCloud / Nuage etc.:**\n",
    "\n",
    "Set the `input` parameter as the direct download link URL. (The training script will download the file and unzip it to a directory when run). Enclose the address with quotes and with `r` at the front. For example:\n",
    "\n",
    "`params['input_source'] = r'https://nuage.osupytheas.fr/s/crYrKyXdQqAR5E6/download'`\n",
    "\n",
    "**Folder on Google Drive**\n",
    "\n",
    "Use the path to the folder on Google Drive. To easily get the path, navigate to the base folder of the dataset in the *Files* tab, right-click the folder and select *Copy Path*. For example:\n",
    "\n",
    "`params['input_source'] = r'/content/drive/My Drive/datasets/DATASET_NAME'`\n",
    "\n",
    "**Folder transferred from computer**\n",
    "\n",
    "Use the path to the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2Toc7zkD61h",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment (remove the hash symbol) the line corresponding to the method used:\n",
    "\n",
    "# Zip file from cloud storage:\n",
    "params['input_source'] = r'https://1drv.ws/u/s!AiQM7sVIv7fah4MN2gWCXDWX_DT0OA?e=Eu3lZh'\n",
    "\n",
    "# Folder on Google Drive\n",
    "# params['input_source'] = r'/content/datasets/DATASET_NAME'\n",
    "\n",
    "# Folder transferred from computer\n",
    "# params['input_source'] = r'/content/drive/My Drive/datasets/DATASET_NAME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIh2ZmpGFv7E"
   },
   "source": [
    "### 3. Input Options\n",
    "\n",
    "Other input parameters are:\n",
    "\n",
    "#### Minimum count per class\n",
    "\n",
    "For training to work well there should be a minimum number of examples in each class. We recommend at least 40, and ideally 200, but it depends on how variable the images are in the dataset. Setting `data_min_count` excludes any classes which have fewer than that many images.\n",
    "\n",
    "If desired, the images from classes with less than `data_min_count` examples can be collected into a single _others_ class by setting `data_map_others` to `True`.\n",
    "\n",
    "#### Test / train split\n",
    "\n",
    "A random proportion of the dataset is set aside for testing / validation. That is, it is not used in training and is instead used to evaluate the accuracy of the network. The proportion of test images is usually around 20% and is set with `data_split`. The split between test and train is normally random, but you can set the random `seed` to an integer ensure the same random ordering is used if necessary.\n",
    "\n",
    "When using N-fold cross-validation we can also set `data_split_offset`. This chooses the fold that is used in training. E.g. if the split is 0.2 (20%) then we may select 0, 1, 2, 3, or 4 to use the respective 20% as the test data.\n",
    "\n",
    "We do NOT use a validation set, training is stopped based on training loss!\n",
    "\n",
    "#### Class weights\n",
    "\n",
    "If the dataset is heavily unbalanced with lots of images in only a few classes, training may give good accuracy on those classes at the expense of accuracy for the classes with few images. To account for this, we can weight the importance of the classes according to their counts by settings `use_class_weights` to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHapYsQGM7Uz",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params['data_min_count'] = 40\n",
    "params['data_map_others'] = False\n",
    "\n",
    "params['data_split'] = 0.20\n",
    "params['data_split_offset'] = 0\n",
    "params['seed'] = None\n",
    "\n",
    "params['use_class_weights'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAkeCZMbD7nA"
   },
   "source": [
    "### 4. Output Location\n",
    "\n",
    "The output location specifies where the training results (trained CNN model, graphs, etc) will be saved on Google Colab.\n",
    "\n",
    "You can save them in the Google Colab:\n",
    "\n",
    "`params['output_dir'] = r'/content/output/'`\n",
    "\n",
    "Or in your Google Drive folder, e.g.:\n",
    "\n",
    "`params['output_dir'] = r'/content/drive/My Drive/output/'`\n",
    "\n",
    "Saving to Google Drive has the advantage that the results will be synced to your computer automatically if you have Google Drive installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sECIvx11sYHD",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Save to Google Colab:\n",
    "params['output_dir'] = r'/content/output/'\n",
    "\n",
    "# Save to Google Drive\n",
    "# params['output_dir'] = r'/content/drive/My Drive/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKpDY_XSFGyv"
   },
   "source": [
    "**Note:** For Google Drive, if you have not already done so, the drive must be mounted on Google Colab but running the following cell and entering the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLilDOBbFFHC",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trEWIMeYNVSY"
   },
   "source": [
    "### 5. Output Options\n",
    "\n",
    "#### Model Format\n",
    "\n",
    "There are three option to save the model (trained network) using the `save_model` parameter:\n",
    "\n",
    "*  `None`: Don't save the model\n",
    "*  `saved_model`: Save the model in Tensorflow saved model format\n",
    "*  `frozen`: Freeze and save the model **(recommended)**\n",
    "\n",
    "The `frozen`method is recommended so that the trained network can be used in the *ParticleTrieur* program. Models can be quite large (20 - 100MB depending on type).\n",
    "\n",
    "#### Estimate mislabeled\n",
    "\n",
    "If enabled, mislabeled images in the training (and test) dataset are estimated by using k-NN to compare the CNN feature vector (output of penultimate dense layer) with other images, and flagging those images where the more similar images belong to a different class. \n",
    "\n",
    "E.g. if the image is labeled in class A but the more similar images are in class B, it will be flagged as mislabeled. A figure is generated for each potentially mislabeled image in the output directory. Set `save_mislabeled` to `True` to enable this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUNQEVhKPh06",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params['save_model'] = 'frozen'\n",
    "params['save_mislabeled'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xAhsQoznnhw7"
   },
   "source": [
    "### 6. Convolutional Neural Network\n",
    "\n",
    "The type of convolutional neural network determines the accuracy of classification, the time to finish training and the size of the network files.\n",
    "\n",
    "We recommend starting with the `resnet50_cyclic_tl` network to get an idea of the rough accuracy for your dataset and to check that everything is running correctly.\n",
    "\n",
    "The types available are:\n",
    "\n",
    "#### Base / ResNet Cyclic (Custom)\n",
    "\n",
    "Codes: `base_cyclic, resnet_cyclic`\n",
    "\n",
    "These CNNs was developed at CEREGE for using with foraminifera particle images. The `base_cyclic` design uses blocks of two convolutional layers, while the `resnet_cyclic` design uses ResNet-style blocks. \n",
    "\n",
    "They include *cyclic layers* that give some rotational invariance internal to the network. The recommened input is greyscale images (single channel) with size 128 x 128 pixels.\n",
    "\n",
    "The networks also has some extra parameters:\n",
    "\n",
    "*   `filters`: Number of filters in the first convolution layer (default: 4)\n",
    "*   `use_batch_norm`: Use batch norm layers (default: True)\n",
    "*   `global_pooling`: Use average (`avg`), maximum (`max`) or no global pooling layer (`None`) (default: None)\n",
    "*   `activation`: Use ReLU (`relu`), ELU (`elu`) or SeLU (`selu`) for the activation function (default: relu)\n",
    "\n",
    "#### Transfer Learning (Fast)\n",
    "\n",
    "Codes: `resnet50_tl, resnet50_cyclic_tl, resnet50_cyclic_gain_tl`\n",
    "\n",
    "This uses a ResNet50 network that has been pre-trained on ImageNet to generate feature vectors which are then trained in a two-layer flat network. It is almost as accurate as the previous network types but much much faster to train. \n",
    "\n",
    "The cost of the increased speed is that no image augmentation is performed. The cyclic and gain variants add some internal variation to the network to compensate, using cylic layers and random gain layers before the ResNet50 model, respectively.\n",
    "\n",
    "#### Pre-constructed (Keras Applications)\n",
    "\n",
    "The MISO library includes the classification_models library from https://github.com/qubvel/classification_models\n",
    "\n",
    "You can use any of the models described in the above link (which includes accuracy and running times for the ImageNet training set): `vgg16, vgg19, resnet18, resnet34, resnet50, resnet101, resnet152, resnet50v2, resnet101v2, resnet152v2, resnext50, resnext101, densenet121, densenet169, densenet201, inceptionv3, xception, inceptionresnetv2, seresnet18, seresnet34, seresnet50, seresnet101, seresnet152, seresnext50, seresnext101, senet154, nasnetlarge, nasnetmobile, mobilenet, mobilenetv2`.\n",
    "\n",
    "The image size and type (colour or grayscale) are also described. Most of these networks are designed for very large training sets with lots of classes, and therefore take a long time to train. We recommend trying these networks as a first step:\n",
    "\n",
    "*    `resnet18`: ResNet-style network with 18 layers. ResNet networks use skip connections to help propogate small features to the deeper layers.\n",
    "*    `seresnet18`: Same as `resnet18` but with squeeze excitation layers\n",
    "*    `densenet121`: DenseNet-style network with 121 layers. DenseNet network use lots of layers with only a small number of filters, where every layer is connected to the layers following it, inside a block.\n",
    "*    `mobilenetv2`: A small, accurate network that is fast to train.\n",
    "\n",
    "These four designs use 224 x 224 images, however we have found that larger images may give better results. Either colour or grayscale can be used.\n",
    "\n",
    "#### Image Size\n",
    "\n",
    "Finally, the image size must be selected.\n",
    "\n",
    "Choose the appropriate width and height (these must be the same!) and number of channels, 1 for grayscale, 3 for colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNsjCfBxmFCU",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params['type'] = 'resnet50_cyclic_tl'\n",
    "params['img_height'] = 224\n",
    "params['img_width'] = 224\n",
    "params['img_channels'] = 3\n",
    "\n",
    "# Custom parameters for base_cyclic and resnet_cyclic\n",
    "params['filters'] = 4\n",
    "params['use_batch_norm'] = True\n",
    "params['global_pooling'] = None\n",
    "params['activation'] = 'relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SG6H9qJwqjWA"
   },
   "source": [
    "### 7. Training\n",
    "\n",
    "#### Batch size\n",
    "\n",
    "A default batch size of 64 is used for training. The batch size can be reduced if there are out-of-memory errors, however this should not be a problem on Google Colab.\n",
    "\n",
    "#### Adaptive learning rate (ALR)\n",
    "\n",
    "When training the network, the learning rate (how rapidly the network weights are allowed to change) is dropped by half whenever the improvement in loss (how well the network fits the training data) reaches a plateau. The plateau is detected by looking at the loss over the most recent number of epochs. Training is stopped after this plateau is reached a certain number of times.\n",
    "\n",
    "This adaptive learning rate system is controlled by two parameters:\n",
    "\n",
    "*   `alr_epochs`: The number of epochs (complete runs through the training data) to consider when detecting the plateau.\n",
    "*   `alr_drops`: The number of times the learning rate is dropped (plateau detected) after which training is stopped.\n",
    "\n",
    "A larger `alr_epochs` will result in better accuracy but longer training time, with diminishing returns. From experience we have found that a value of 40 works well for datasets with about 200 images per class, and 5-10 for large datasets with 1000+ images per class.\n",
    "\n",
    "#### Maximum limit\n",
    "\n",
    "There is another parameter `max_drops` that sets the maximum number of epochs after which training will be stopped regardless. Typically we set this to a high number, as the ALR system will usually stop training before this is reached. However, you can also set it to a very small number, e.g. 2, to quickly run the training just to check everything is working, before set back to a high number, e.g. 10000, for proper training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QT8BMPr-vM3g",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params['batch_size'] = 64\n",
    "params['alr_epochs'] = 40\n",
    "params['alr_drops'] = 4\n",
    "params['max_epochs'] = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCkLlA0hvSb9"
   },
   "source": [
    "## Execution\n",
    "\n",
    "Now that the parameters have been configured, run the cell below to start training!\n",
    "\n",
    "The output will show, in order:\n",
    "\n",
    "*   Loading of the images and if any classes have been skipped due to too few images.\n",
    "*   The topography of the network (layers and dimensions).\n",
    "*   A text-based graph showing the progress of training in real-time.\n",
    "*   Loss and accuracy graphs.\n",
    "*   Confusion matrix with precision and recall bar graphs.\n",
    "\n",
    "Training can take a long time depending on the type of network, size of the dataset and number of ALR epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 159489,
     "status": "ok",
     "timestamp": 1565866071529,
     "user": {
      "displayName": "Ross Marchant",
      "photoUrl": "",
      "userId": "18161906969163655277"
     },
     "user_tz": -600
    },
    "id": "0_gr5wTNvNvn",
    "outputId": "03137440-ff8e-4829-927d-6f8ed2c44c9e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model, vector_model, datasource, result = train_image_classification_model(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2nqvKlM8-D5A"
   },
   "source": [
    "***\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "# Results\n",
    "\n",
    "The results of training are saved in the output folder, under the network name and the date and time of training.\n",
    "\n",
    "## Saved Files\n",
    "\n",
    "###Model\n",
    "\n",
    "The model folder contains two versions of the saved model.\n",
    "\n",
    "*   `saved_model.pb` and the `variables` directory contain the model saved in Tensorflow Saver format.\n",
    "*   `frozen_model.pb` is the model that has been frozen and is ready for use in classification programs.\n",
    "*   `network_info.xml` is an XML description of the frozen model that describes the structure of the model (e.g. which tensors are used for input and output) and the class labels.\n",
    "\n",
    "###Mislabeled\n",
    "\n",
    "The *Mislabeled* directory contains some plots showing images that may have been mislabeled when creating the dataset.\n",
    "\n",
    "It does this by generating a *feature vector* from the output the second-last dense layer of the network, for each image. The vectors are compared using k-NN for each image. If the class of image predicted using k-NN is different to the label given to the image it is flagged as possibly mislabeled.\n",
    "\n",
    "###Downloading\n",
    "\n",
    "Each file can be downloaded individually from the output folder.\n",
    "\n",
    "If you want to download all files at once, create a zip of the folder:\n",
    "\n",
    "*   Locate the folder containing the output files in the *Files* tab.\n",
    "*   Right-click on it and select *Copy Path*.\n",
    "*   Paste the path in the cell below and run it.\n",
    "*   Right-click *output.zip* and select *Download*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qHxX8F3aDJpx",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!zip -r /content/output.zip PAST_PATH_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NbLQCRE-B1eu"
   },
   "source": [
    "\n",
    "## Python output\n",
    "\n",
    "The training function also returns python variables that can be used for further inference\n",
    "\n",
    "*   `model`: The trained Keras model.\n",
    "*  `vector_model`: Sub-model of the trained model that outputs the feature vector.\n",
    "*   `datasource`: The training and test images and class labels.\n",
    "*   `result`: The results of training: accuracy and per-class precision and recall.\n",
    "\n",
    "Run the cell below to print the attributes of each object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1565866228791,
     "user": {
      "displayName": "Ross Marchant",
      "photoUrl": "",
      "userId": "18161906969163655277"
     },
     "user_tz": -600
    },
    "id": "zUqjYyKd8B4G",
    "outputId": "566aaa5b-88b4-4211-a484-ef8eb3979f29",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def print_attributes(obj, name):\n",
    "  print(\"---------------------------------------------------------------------\")\n",
    "  print(name + \":\")\n",
    "  print(\"---------------------------------------------------------------------\")\n",
    "  print(\"\\n\".join([attr for attr in dir(obj) if not attr.startswith('__')]))\n",
    "  print()\n",
    "  \n",
    "print_attributes(result, \"result\")\n",
    "print_attributes(datasource, \"datasource\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification_with_miso_tutorial.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/microfossil/particle-classification-examples/blob/master/image_classification_with_miso_tutorial.ipynb",
     "timestamp": 1563941676161
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification_with_miso_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ycmylt-ISHE",
        "colab_type": "text"
      },
      "source": [
        "# Welcome\n",
        "\n",
        "This python notebook is a step-by-step guide to training a neural network on Google Colab using the MISO library.\n",
        "\n",
        "The MISO library is a set of python scripts that simplify creating, training and saving a convolutional neural network (CNN) primarily for particle images, such as foraminifera.\n",
        "\n",
        "The MISO library can be used to train common CNN topologies such as ResNet, and also includes a custom CNN design, \"base_cyclic\", that was developed at CEREGE and gives good results with quick training time.\n",
        "\n",
        "Training assumes single particle images with the particles roughly centred in the image, and saved in jpeg, bmp, tiff or png format.\n",
        "\n",
        "**Note:** The notebook is interactive, you can run the code inside it. Code cells are coloured light grey. To run a cell, click it or hover the mouse above it and click the play arrow on the left.\n",
        "\n",
        "# Getting Started\n",
        "\n",
        "## Save a copy (recommended)\n",
        "\n",
        "If you want to keep a copy of this notebook and any changes you make, please make a copy:\n",
        "\n",
        "*   Click *File* -> *Save a copy in Drive...* to save this notebook in your Google Drive.\n",
        "*   A new Google Colab tab will open up with a copy of the notebook.\n",
        "*   Click *File* -> *Rename...* to give the notebook a more memorable name.\n",
        "\n",
        "## Enabling the GPU (Important)\n",
        "\n",
        "For fast training we need to enable the GPU. \n",
        "\n",
        "In the menu bar of the Google Colab webpage, click *Runtime* -> *Change runtime type* and in the dialog that pops up, change *Hardware accelerator* to *GPU*. Click save to restart Google Colab with a GPU.\n",
        "\n",
        "**Note:** You can check which GPU has been enabled using the `!nvidia-smi` command. The `T4` is 3-4 times faster than the `K80`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC4iePqExWwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "369hf0uij2aU",
        "colab_type": "text"
      },
      "source": [
        "## MISO library\n",
        "\n",
        "The MISO python library contains the code for creating and training the neural networks.\n",
        "\n",
        "It must be installed from its bitbucket repository. \n",
        "\n",
        "**Note:** Google Colab will prompt you (at the bottom of the cell) to restart the runtime if you have already installed the library this session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwndK5weDskf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U git+https://systrifor:Cerege2018@bitbucket.org/projetfirst/particleclassification.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iWr-2GtIvaL",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "## Preparation\n",
        "\n",
        "To use an image dataset for training, it must be uploaded to Google Colab\n",
        "\n",
        "Before uploading the images must be put into the correct directory structure and then compressed to a zip file.\n",
        "\n",
        "The structure is a single folder with the name of the dataset, containing subfolders with the names of each class. Inside each subfolder are the images for the corresponding class.\n",
        "\n",
        "There are two methods to do this:\n",
        "\n",
        "*   Upload the data onto your Google Drive\n",
        "*   Upload the data from your computer\n",
        "*   Have Google Colab download the data from a sharing service such as Dropbox\n",
        "\n",
        "\n",
        "**Before continuing:**\n",
        "\n",
        "> If not already open, click the small arrow under the Colab icon (CO) in the upper left corner of the webpage to open the left pane, and then go to the *Files* tab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSfqMSnoat04",
        "colab_type": "text"
      },
      "source": [
        "## Use Google Drive (Recommended)\n",
        "\n",
        "Googe Drive is a sharing service that gives about 15GB of storage. Everyone with a Google account automatically has a Google Drive account. \n",
        "\n",
        "### 1. Upload to Google Drive\n",
        "\n",
        "Create a datasets directory on your Google Drive and save the dataset folder to it. This can either be done online, or by syncing with your Google Drive on your computer.\n",
        "\n",
        "To download the computer software, go to https://drive.google.com/drive/my-drive, click the settings icon (gear icon in top right) and then click *Get Backup and Sync for Windows*.\n",
        "\n",
        "### 2. Mount the drive\n",
        "\n",
        "Run the cell below to mount the drive on Google Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n36XODPXan0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNWPJWJufgva",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Upload from computer\n",
        "\n",
        "Uploading from a computer is easy, but if you have a slow connection it can be a pain to upload the data every time you want to do some training.\n",
        "\n",
        "### 1. Create a directory\n",
        "\n",
        "Create a directory for the datasets to be stored in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scXgjwLtV17C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"/content/datasets/\", exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU53m21IZT7b",
        "colab_type": "text"
      },
      "source": [
        "### 2. Create a zip file\n",
        "\n",
        "Compress the root folder of the dataset into a .zip file:\n",
        "\n",
        "* Windows:\n",
        "* Mac:\n",
        "\n",
        "### 3. Upload the zip file\n",
        "\n",
        "In the *Files* tab in the left pane of Google Colab, right-click the newly created *datasets* directory and click *Upload*.\n",
        "\n",
        "Choose the zip file and start the upload. The progress is shown at the bottom of the *Files* tab.\n",
        "\n",
        "### 4. Unzip\n",
        "\n",
        "Once the file has uploaded, right-click the filename in the *Files* pane, and click *Copy path*.\n",
        "\n",
        "Paste the copied path in the cell below (replacing PASTE_HERE) and run it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1s5XkbVcB71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip PASTE_HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbpIfpJ7fHjj",
        "colab_type": "text"
      },
      "source": [
        "You should see a new folder *drive* in the *Files* tab. If not, click *Refresh*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP-Q1L5QVnuj",
        "colab_type": "text"
      },
      "source": [
        "## Download from a sharing service\n",
        "\n",
        "Uploading from a sharing service is quick once you have the data in the cloud.\n",
        "\n",
        "### 1. Create a zip file\n",
        "\n",
        "Compress the root folder of the dataset into a .zip file:\n",
        "\n",
        "* Windows:\n",
        "* Mac:\n",
        "\n",
        "### 2. Upload\n",
        "\n",
        "Upload the zip file onto your favourite cloud sharing provider, e.g. Dropbox and Onedrive\n",
        "\n",
        "### 3. Create a sharing link\n",
        "\n",
        "Create a sharing link for the file. For example, in Windows, right-click your zip file in the dropbox folder and select *Copy Dropbox Link*\n",
        "\n",
        "### 4. Convert the link into a direct download link\n",
        "\n",
        "For some sharing services such as Dropbox and Onedrive, the sharing link points to a website where you can download the file. We need a direct download link to the file instead.\n",
        "\n",
        "The link must be changed from the website link to the direct download link.\n",
        "\n",
        "**Dropbox:**\n",
        "\n",
        "Change *www.dropbox.com* to *dl.dropboxusercontent.com*:\n",
        "\n",
        "For example, \n",
        "\n",
        "https://www.dropbox.com/s/wlxcp29u8t0z9yw/DummyFile.TXT?dl=0\n",
        "\n",
        "becomes\n",
        "\n",
        "https://dl.dropboxusercontent.com/s/wlxcp29u8t0z9yw/DummyFile.TXT?dl=0\n",
        "\n",
        "**OneDrive:**\n",
        "\n",
        "Change the *ms* in the first part of the link to *ws*.\n",
        "\n",
        "For example,\n",
        "\n",
        "https://1drv.ms/u/s!AiQM7sVIv7fah4IZlw0GmHAwmOT9DY\n",
        "\n",
        "becomes\n",
        "\n",
        "https://1drv.ws/u/s!AiQM7sVIv7fah4IZlw0GmHAwmOT9DY\n",
        "\n",
        "**Other services:**\n",
        "\n",
        "For other services, check if the sharing link is a direct download link by pasting it into the address bar of your internet browser and pressing enter.\n",
        "\n",
        "If the zip file starts downloading, it is a direct download link already, and nothing needs to be changed. If it goes to a website, you may need to search how to change it to a direct download link for you particular service.\n",
        "\n",
        "### 7. Download\n",
        "\n",
        "The final step is to download the data to Google Colab\n",
        "\n",
        "Replace the sharing link address in the cell below with the direct download:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYFWkmjxLP9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from miso.data.download import download_images\n",
        "\n",
        "sharing_link = \"https://1drv.ws/u/s!AiQM7sVIv7fah4IZlw0GmHAwmOT9DA\"\n",
        "\n",
        "download_images(sharing_link, \"/content/datasets/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqp2JbVbOHLp",
        "colab_type": "text"
      },
      "source": [
        "Now click *Refresh* in the *Files* tab in the left pane of the Google Colab screen. You should see  a new directory called datasets that contains the dataset folder.\n",
        "\n",
        "**Note:** If you want to download another dataset, please delete the file *tmp_download.zip* from the *datasets* folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-FLidQAkdsc",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "We shall use the simple training interface provided by the MISO python library.\n",
        "\n",
        "It allows us to train the dataset using a variety of pre-made neural network topologies. The results and the trained neural network are saved on Google Colab for download.\n",
        "\n",
        "**Note:** The directories on Google Colab are cleared after each session. Remember to download the results before quitting!\n",
        "\n",
        "## Configuration\n",
        "\n",
        "### 1. Setup\n",
        "\n",
        "First we load the training method and create a dictionary to hold the configuration parameters.\n",
        "\n",
        "The `default_params` function is used to initialise the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIyj-kV5mVix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from miso.training.model_trainer import train_image_classification_model\n",
        "from miso.training.model_params import default_params\n",
        "\n",
        "params = default_params()\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bedphLXk4-o",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Add a short name and description for the network.\n",
        "\n",
        "*   The short name will be used to identify the network and construct the output save directory.\n",
        "*   The description can be a more in-depth summary of the network and dataset. Set to *None* to have the description automatically generated.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5CtNXhpk1j3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params['name'] = 'google_colab_example'\n",
        "params['description'] = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ht3qh8hq17e",
        "colab_type": "text"
      },
      "source": [
        "### 2. Input and output\n",
        "\n",
        "Add the location of the input data, along with a folder where to store the trained models. (Note: that the default folder in Google Colab is called `/content/`)\n",
        "\n",
        "For the input location this will be something like (replacing DATASET_NAME with the name of the dataset root folder):\n",
        "\n",
        "*    `/content/drive/datasets/DATASET_NAME` for the Google Drive method\n",
        "*    `/content/datasets/DATASET_NAME` for the other methods\n",
        "\n",
        "To easily get the path, navigate to the base folder of the dataset in the *Files* tab, right-click the folder and select *Copy Path*\n",
        "\n",
        "For the output location is recommended to save to the Google Drive if possible, so that the results will be synced automatically. E.g.\n",
        "\n",
        "*   `/content/drive/output/DATASET_NAME` for the Google Drive method.\n",
        "*   `/content/output/DATASET_NAME` for the other methods.\n",
        "\n",
        "####Minimum count per class\n",
        "\n",
        "For training to work well there should be a minimum number of examples in each class. We recommend at least 40, and ideally 200, but it depends on how variable the images are in the dataset. Setting `data_min_count` excludes any classes where the dataset has less than that many images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sECIvx11sYHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_NAME = \"modern_coretop\"\n",
        "params['input_dir'] = r'/content/datasets/' + DATASET_NAME\n",
        "params['output_dir'] = r'/content/output/' + DATASET_NAME\n",
        "params['data_min_count'] = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAhsQoznnhw7",
        "colab_type": "text"
      },
      "source": [
        "### 3. Type\n",
        "\n",
        "The type of neural network determines the accuracy of classification, the time to finish training and the size of the network files.\n",
        "\n",
        "The types available are:\n",
        "\n",
        "####Base Cyclic#### \n",
        "\n",
        "Codes: base_cyclic\n",
        "\n",
        "This CNN was developed at CEREGE for using with foraminifera particle images. It includes *cyclic layers* that give some rotational invariance internal to the network. The recommened input is greyscale images (single channel) with size 128 x 128 pixels.\n",
        "\n",
        "This network also has some extra parameters:\n",
        "\n",
        "*   `filters`: Number of filters in the first convolution layer (default: 4)\n",
        "\n",
        "####ResNet####\n",
        "\n",
        "Codes: resnet18, resnet34, resnet50, resnet101, resnet150\n",
        "\n",
        "ResNet is a popular, high-perfoming CNN that uses *skip connections* to ensure that both small and large features propogate to the final classification layers. The recommended input is colour images (RGB) with size 224 x 224 pixels.\n",
        "\n",
        "There are multiple sizes of ResNet, from 18 layers to 150 layers. The larger networks with more layers take longer to train.\n",
        "\n",
        "####Transfer Learning####\n",
        "\n",
        "Not implemented yet!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GNsjCfBxmFCU",
        "colab": {}
      },
      "source": [
        "params['type'] = 'resnet18'\n",
        "params['img_height'] = 128\n",
        "params['img_width'] = 128\n",
        "params['img_channels'] = 1\n",
        "\n",
        "# Custom parameters for base_cyclic\n",
        "params['filters'] = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG6H9qJwqjWA",
        "colab_type": "text"
      },
      "source": [
        "### 4. Training configuration\n",
        "\n",
        "A default batch size of 64 is used for training. The batch size can be reduced if there are out-of-memory errors, however this should not be a problem on Google Colab\n",
        "\n",
        "####Adaptive learning rate (ALR)\n",
        "\n",
        "When training the network, the learning rate (how rapidly the network weights are allowed to change) is dropped by half whenever the improvement in loss (how well the network fits the training data) reaches a plateau. The plateau is detected by looking at the loss over the most recent number of epochs. Training is stopped after this plateau is reached a certain number of times.\n",
        "\n",
        "This adaptive learning rate system is controlled by two parameters:\n",
        "\n",
        "*   `alr_epochs`: The number of epochs (complete runs through the training data) to consider when detecting the plateau.\n",
        "*   `alr_drops`: The number of times the learning rate is dropped (plateau detected) after which training is stopped.\n",
        "\n",
        "A larger `alr_epochs` will result in better accuracy but longer training time, with diminishing returns. From experience we have found that a value of 40 works well for datasets with about 200 images per class, and 5-10 for large datasets with 1000+ images per class.\n",
        "\n",
        "####Maximum limit\n",
        "\n",
        "There is another parameter `max_drops` that sets the maximum number of epochs after which training will be stopped regardless. Typically we set this to a high number, as the ALR system will usually stop training before this is reached. However, you can also set it to a very small number, e.g. 2, to quickly run the training to just check everything is working, before set back to a high number, e.g. 10000, for proper training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QT8BMPr-vM3g",
        "colab": {}
      },
      "source": [
        "params['batch_size'] = 64\n",
        "params['alr_epochs'] = 40\n",
        "params['alr_drops'] = 4\n",
        "params['max_epochs'] = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCkLlA0hvSb9",
        "colab_type": "text"
      },
      "source": [
        "## Execution\n",
        "\n",
        "Now that the parameters have been configured, run the cell below to start training!\n",
        "\n",
        "The output will show, in order:\n",
        "\n",
        "*   Loading of the images and if any classes have been skipped due to too few images.\n",
        "*   The topography of the network (layers and dimensions).\n",
        "*   A text-based graph showing the progress of training in real-time.\n",
        "*   Loss and accuracy graphs.\n",
        "*   Confusion matrix with precision and recall bar graphs.\n",
        "\n",
        "Training can take a long time depending on the type of network, size of the dataset and number of ALR epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_gr5wTNvNvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, datasource, result = train_image_classification_model(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nqvKlM8-D5A",
        "colab_type": "text"
      },
      "source": [
        "# Outputs\n",
        "\n",
        "The results of training are saved in the output folder, under the network name and the date and time of training.\n",
        "\n",
        "## Saved Files\n",
        "\n",
        "###Model\n",
        "\n",
        "The model folder contains two versions of the saved model.\n",
        "\n",
        "*   `saved_model.pb` and the `variables` directory contain the model saved in Tensorflow Saver format.\n",
        "*   `frozen_model.pb` is the model that has been frozen and is ready for use in classification programs.\n",
        "*   `network_info.xml` is an XML description of the frozen model that describes the structure of the model (e.g. which tensors are used for input and output) and the class labels.\n",
        "\n",
        "###Mislabeled\n",
        "\n",
        "The *Mislabeled* directory contains some plots showing images that may have been mislabeled when creating the dataset.\n",
        "\n",
        "It does this by generating a *feature vector* from the output the second-last dense layer of the network, for each image. The vectors are compared using k-NN for each image. If the class of image predicted using k-NN is different to the label given to the image it is flagged as possibly mislabeled.\n",
        "\n",
        "###Downloading\n",
        "\n",
        "Each file can be downloaded individually from the output folder.\n",
        "\n",
        "If you want to download all files at once, create a zip of the folder:\n",
        "\n",
        "*   Locate the folder containing the output files in the *Files* tab.\n",
        "*   Right-click on it and select *Copy Path*.\n",
        "*   Paste the path in the cell below and run it.\n",
        "*   Right-click *output.zip* and select *Download*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHxX8F3aDJpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/output.zip PAST_PATH_HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbLQCRE-B1eu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Python output\n",
        "\n",
        "The training function also returns python variables that can be used for further inference\n",
        "\n",
        "*   `model`: The trained Keras model.\n",
        "*   `datasource`: The training and test images and class labels.\n",
        "*   `result`: The results of training: accuracy and per-class precision and recall.\n",
        "\n",
        "Run the cell below to print the attributes of each object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUqjYyKd8B4G",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "def print_attributes(obj, name):\n",
        "  print(\"---------------------------------------------------------------------\")\n",
        "  print(name + \":\")\n",
        "  print(\"---------------------------------------------------------------------\")\n",
        "  print(\"\\n\".join([attr for attr in dir(obj) if not attr.startswith('__')]))\n",
        "  print()\n",
        "  \n",
        "print_attributes(result, \"result\")\n",
        "print_attributes(datasource, \"datasource\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}